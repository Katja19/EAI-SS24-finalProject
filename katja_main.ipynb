{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EAI Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of zenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to create a new ZenML project\n",
    "#!rm -rf .zen # don't work under windows, cause it's a unix-command\n",
    "!rmdir /S /Q .zen\n",
    "!zenml init\n",
    "!zenml integration install sklearn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are checking the status of the stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to install the MLFlow integration, which is a very popular open-source platform for managing the end-to-end machine learning lifecycle\n",
    "#!zenml integration install mlflow -y\n",
    "!zenml integration install wandb -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to register the MLFlow integration for the experiment tracker, which is the component that tracks the experiments and logs the results\n",
    "import os\n",
    "api_key_wandb = os.environ['WANDB_API_KEY']\n",
    "!zenml experiment-tracker register wandb_experiment_tracker --flavor=wandb --api_key=$api_key_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack register wandb_stack -a default -o default -e wandb_experiment_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint__: if the stack does not show the mlflow integration, check in the terminal if the mlflow is installed with  \n",
    "- zenml experiment-tracker list  \n",
    "- zenml model-deployer list  \n",
    "- zenml stack list  \n",
    "- activate the mlflow with: zenml stack set mlflow_stack  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the stack to the mlflow stack\n",
    "!zenml stack set wandb_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At last we are going to check the status of the stack again\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import run_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model variant and type\n",
    "m_variant = \"multi\"\n",
    "m_type = \"xgboost\"\n",
    "#m_type = \"random_forest\"\n",
    "lags = 1\n",
    "tials = 5\n",
    "\n",
    "run_pipelines(model_variant=m_variant, model_type=m_type, lags=lags, trials=tials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experimentlal tracking we used weights & biases  \n",
    "\n",
    "https://wandb.ai/ss24_eai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to visualize the pipeline runs in wandb\n",
    "#project_name = \"forecasting_model_mutivariant\"\n",
    "\n",
    "#!wandb agent $project_name/forecasting_model_multivariant --count 1 --project $project_name --queue forecasting_model_multivariant --entity $project_name --start-time now --duration 1h\n",
    "#!wandb agent --help\n",
    "#!wandb agent -p forecasting_model_multivariant abc123\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zenml.client import Client\n",
    "# pipeline_run = Client().get_pipeline(\"training_pipeline\").last_run\n",
    "# step = pipeline_run.steps[\"evaluate_model\"]\n",
    "# experiment_tracker_url = step.run_metadata[\"experiment_tracker_url\"].value\n",
    "# experiment_tracker_url # jedes mal wenn code space neu geöffnet wird ändert sich dieser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "# from zenml.client import Client\n",
    "\n",
    "# client = Client()\n",
    "# report = client.get_artifact_version(\"training_pipeline\").load()\n",
    "\n",
    "# display(HTML(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nun erst die inference = Using the best model????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
