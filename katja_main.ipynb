{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EAI Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of zenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\n",
      "⠋ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\n",
      "⠹ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\n",
      "⠸ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\n",
      "⠴ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\u001b[1;35mSetting the repo active workspace to 'default'.\u001b[0m\n",
      "\u001b[33mSetting the repo active stack to default.\u001b[0m\n",
      "\n",
      "ZenML repository initialized at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "⠦ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\n",
      "⠦ Initializing ZenML repository at \n",
      "c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject.\n",
      "\n",
      "\n",
      "The local active stack was initialized to 'default'. This local configuration \n",
      "will only take effect when you're running ZenML from the initialized repository\n",
      "root, or from a subdirectory. For more information on repositories and \n",
      "configurations, please visit \n",
      "https://docs.zenml.io/user-guide/starter-guide/understand-stacks.\n",
      "⠋ Installing integrations...\n",
      "⠙ Installing integrations...\n",
      "⠹ Installing integrations...\n",
      "⠸ Installing integrations...\n",
      "⠼ Installing integrations...\n",
      "⠴ Installing integrations...\n",
      "⠦ Installing integrations...\n",
      "⠇ Installing integrations...\n",
      "⠏ Installing integrations...\n",
      "⠋ Installing integrations...\n",
      "⠙ Installing integrations...\n",
      "⠹ Installing integrations...\n",
      "⠸ Installing integrations...\n",
      "⠴ Installing integrations...\n",
      "⠦ Installing integrations...\n",
      "⠦ Installing integrations...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we are going to create a new ZenML project\n",
    "#!rm -rf .zen # don't work under windows, cause it's a unix-command\n",
    "!rmdir /S /Q .zen\n",
    "!zenml init\n",
    "!zenml integration install sklearn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Stack Configuration        \n",
      "┌────────────────┬────────────────┐\n",
      "│ COMPONENT_TYPE │ COMPONENT_NAME │\n",
      "├────────────────┼────────────────┤\n",
      "│ ARTIFACT_STORE │ default        │\n",
      "├────────────────┼────────────────┤\n",
      "│ ORCHESTRATOR   │ default        │\n",
      "└────────────────┴────────────────┘\n",
      "     'default' stack (ACTIVE)      \n",
      "⠋ Describing the stack...\n",
      "\n",
      "No labels are set for this stack.\n",
      "⠋ Describing the stack...\n",
      "\n",
      "Stack 'default' with id '55222316-9ac8-47bc-97de-829f73a8a621' is unowned.\n",
      "⠋ Describing the stack...\n",
      "\n",
      "⠋ Describing the stack...\n",
      "\n",
      "\n",
      "You can display various ZenML entities including pipelines, runs, stacks and \n",
      "much more on the ZenML Dashboard. You can try it locally, by running `zenml \n",
      "up`, or remotely, by deploying ZenML on the infrastructure of your choice.\n"
     ]
    }
   ],
   "source": [
    "# First we are checking the status of the stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Installing integrations...\n",
      "⠋ Installing integrations...\n",
      "⠹ Installing integrations...\n",
      "⠸ Installing integrations...\n",
      "⠼ Installing integrations...\n",
      "⠴ Installing integrations...\n",
      "⠦ Installing integrations...\n",
      "⠧ Installing integrations...\n",
      "⠇ Installing integrations...\n",
      "⠏ Installing integrations...\n",
      "⠋ Installing integrations...\n",
      "⠙ Installing integrations...\n",
      "⠹ Installing integrations...\n",
      "⠸ Installing integrations...\n",
      "⠼ Installing integrations...\n",
      "⠴ Installing integrations...\n",
      "⠦ Installing integrations...\n",
      "⠧ Installing integrations...\n",
      "⠧ Installing integrations...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to install the MLFlow integration, which is a very popular open-source platform for managing the end-to-end machine learning lifecycle\n",
    "#!zenml integration install mlflow -y\n",
    "!zenml integration install wandb -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠋ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠙ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠸ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠼ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠴ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠦ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠧ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "⠇ Registering experiment tracker 'wandb_experiment_tracker'...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌───────────────────── Traceback (most recent call last) ─────────────────────┐\n",
      "│ in _run_module_as_main:198                                                  │\n",
      "│ in _run_code:88                                                             │\n",
      "│                                                                             │\n",
      "│ in <module>:7                                                               │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\click\\core.py: │\n",
      "│ 1130 in __call__                                                            │\n",
      "│                                                                             │\n",
      "│   1127 │                                                                    │\n",
      "│   1128 │   def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Any:      │\n",
      "│   1129 │   │   \"\"\"Alias for :meth:`main`.\"\"\"                                │\n",
      "│ > 1130 │   │   return self.main(*args, **kwargs)                            │\n",
      "│   1131                                                                      │\n",
      "│   1132                                                                      │\n",
      "│   1133 class Command(BaseCommand):                                          │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\click\\core.py: │\n",
      "│ 1055 in main                                                                │\n",
      "│                                                                             │\n",
      "│   1052 │   │   try:                                                         │\n",
      "│   1053 │   │   │   try:                                                     │\n",
      "│   1054 │   │   │   │   with self.make_context(prog_name, args, **extra) as  │\n",
      "│ > 1055 │   │   │   │   │   rv = self.invoke(ctx)                            │\n",
      "│   1056 │   │   │   │   │   if not standalone_mode:                          │\n",
      "│   1057 │   │   │   │   │   │   return rv                                    │\n",
      "│   1058 │   │   │   │   │   # it's not safe to `ctx.exit(rv)` here!          │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\click\\core.py: │\n",
      "│ 1657 in invoke                                                              │\n",
      "│                                                                             │\n",
      "│   1654 │   │   │   │   super().invoke(ctx)                                  │\n",
      "│   1655 │   │   │   │   sub_ctx = cmd.make_context(cmd_name, args, parent=ct │\n",
      "│   1656 │   │   │   │   with sub_ctx:                                        │\n",
      "│ > 1657 │   │   │   │   │   return _process_result(sub_ctx.command.invoke(su │\n",
      "│   1658 │   │                                                                │\n",
      "│   1659 │   │   # In chain mode we create the contexts step by step, but aft │\n",
      "│   1660 │   │   # base command has been invoked.  Because at that point we d │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\click\\core.py: │\n",
      "│ 1657 in invoke                                                              │\n",
      "│                                                                             │\n",
      "│   1654 │   │   │   │   super().invoke(ctx)                                  │\n",
      "│   1655 │   │   │   │   sub_ctx = cmd.make_context(cmd_name, args, parent=ct │\n",
      "│   1656 │   │   │   │   with sub_ctx:                                        │\n",
      "│ > 1657 │   │   │   │   │   return _process_result(sub_ctx.command.invoke(su │\n",
      "│   1658 │   │                                                                │\n",
      "│   1659 │   │   # In chain mode we create the contexts step by step, but aft │\n",
      "│   1660 │   │   # base command has been invoked.  Because at that point we d │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\click\\core.py: │\n",
      "│ 1404 in invoke                                                              │\n",
      "│                                                                             │\n",
      "│   1401 │   │   │   echo(style(message, fg=\"red\"), err=True)                 │\n",
      "│   1402 │   │                                                                │\n",
      "│   1403 │   │   if self.callback is not None:                                │\n",
      "│ > 1404 │   │   │   return ctx.invoke(self.callback, **ctx.params)           │\n",
      "│   1405 │                                                                    │\n",
      "│   1406 │   def shell_complete(self, ctx: Context, incomplete: str) -> t.Lis │\n",
      "│   1407 │   │   \"\"\"Return a list of completions for the incomplete value. Lo │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\click\\core.py: │\n",
      "│ 760 in invoke                                                               │\n",
      "│                                                                             │\n",
      "│    757 │   │                                                                │\n",
      "│    758 │   │   with augment_usage_errors(__self):                           │\n",
      "│    759 │   │   │   with ctx:                                                │\n",
      "│ >  760 │   │   │   │   return __callback(*args, **kwargs)                   │\n",
      "│    761 │                                                                    │\n",
      "│    762 │   def forward(                                                     │\n",
      "│    763 │   │   __self, __cmd: \"Command\", *args: t.Any, **kwargs: t.Any  # n │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\zenml\\cli\\stac │\n",
      "│ k_components.py:287 in register_stack_component_command                     │\n",
      "│                                                                             │\n",
      "│    284 │   │                                                                │\n",
      "│    285 │   │   with console.status(f\"Registering {display_name} '{name}'... │\n",
      "│    286 │   │   │   # Create a new stack component model                     │\n",
      "│ >  287 │   │   │   component = client.create_stack_component(               │\n",
      "│    288 │   │   │   │   name=name,                                           │\n",
      "│    289 │   │   │   │   flavor=flavor,                                       │\n",
      "│    290 │   │   │   │   component_type=component_type,                       │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\zenml\\client_l │\n",
      "│ azy_loader.py:198 in _inner                                                 │\n",
      "│                                                                             │\n",
      "│   195 │   │   │   │   │   with contextlib.suppress(ValueError):             │\n",
      "│   196 │   │   │   │   │   │   kwargs[k] = ClientLazyLoader(**v).evaluate()  │\n",
      "│   197 │   │   │                                                             │\n",
      "│ > 198 │   │   │   return func(*args_, **kwargs)                             │\n",
      "│   199 │   │                                                                 │\n",
      "│   200 │   │   return _inner                                                 │\n",
      "│   201                                                                       │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\zenml\\client.p │\n",
      "│ y:2003 in create_stack_component                                            │\n",
      "│                                                                             │\n",
      "│   2000 │   │   )                                                            │\n",
      "│   2001 │   │                                                                │\n",
      "│   2002 │   │   # Register the new model                                     │\n",
      "│ > 2003 │   │   return self.zen_store.create_stack_component(                │\n",
      "│   2004 │   │   │   component=create_component_model                         │\n",
      "│   2005 │   │   )                                                            │\n",
      "│   2006                                                                      │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\zenml\\analytic │\n",
      "│ s\\utils.py:178 in inner_func                                                │\n",
      "│                                                                             │\n",
      "│   175 │   │   │   │   except Exception as e:                                │\n",
      "│   176 │   │   │   │   │   logger.debug(f\"Analytics tracking failure for {fu │\n",
      "│   177 │   │   │   │                                                         │\n",
      "│ > 178 │   │   │   │   result = func(*args, **kwargs)                        │\n",
      "│   179 │   │   │   │                                                         │\n",
      "│   180 │   │   │   │   try:                                                  │\n",
      "│   181 │   │   │   │   │   if isinstance(result, AnalyticsTrackedModelMixin) │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\zenml\\zen_stor │\n",
      "│ es\\sql_zen_store.py:3103 in create_stack_component                          │\n",
      "│                                                                             │\n",
      "│    3100 │   │   \"\"\"                                                         │\n",
      "│    3101 │   │   validate_name(component)                                    │\n",
      "│    3102 │   │   with Session(self.engine) as session:                       │\n",
      "│ >  3103 │   │   │   self._fail_if_component_with_name_type_exists(          │\n",
      "│    3104 │   │   │   │   name=component.name,                                │\n",
      "│    3105 │   │   │   │   component_type=component.type,                      │\n",
      "│    3106 │   │   │   │   workspace_id=component.workspace,                   │\n",
      "│                                                                             │\n",
      "│ C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\zenml\\zen_stor │\n",
      "│ es\\sql_zen_store.py:3384 in _fail_if_component_with_name_type_exists        │\n",
      "│                                                                             │\n",
      "│    3381 │   │   │   .where(StackComponentSchema.type == component_type)     │\n",
      "│    3382 │   │   ).first()                                                   │\n",
      "│    3383 │   │   if existing_domain_component is not None:                   │\n",
      "│ >  3384 │   │   │   raise StackComponentExistsError(                        │\n",
      "│    3385 │   │   │   │   f\"Unable to register '{component_type}' component \" │\n",
      "│    3386 │   │   │   │   f\"with name '{name}': Found an existing \"           │\n",
      "│    3387 │   │   │   │   f\"component with the same name and type in the same │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "StackComponentExistsError: Unable to register 'experiment_tracker' component \n",
      "with name 'wandb_experiment_tracker': Found an existing component with the same\n",
      "name and type in the same  workspace 'default'.\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to register the MLFlow integration for the experiment tracker, which is the component that tracks the experiments and logs the results\n",
    "import os\n",
    "api_key_wandb = os.environ['WANDB_API_KEY']\n",
    "!zenml experiment-tracker register wandb_experiment_tracker --flavor=wandb --api_key=$api_key_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: A stack with name `wandb_stack` already exists, please use a different name.\n"
     ]
    }
   ],
   "source": [
    "!zenml stack register wandb_stack -a default -o default -e wandb_experiment_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint__: if the stack does not show the mlflow integration, check in the terminal if the mlflow is installed with  \n",
    "- zenml experiment-tracker list  \n",
    "- zenml model-deployer list  \n",
    "- zenml stack list  \n",
    "- activate the mlflow with: zenml stack set mlflow_stack  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active repository stack set to: 'wandb_stack'\n",
      "⠋ Setting the repository active stack to 'wandb_stack'...\n",
      "⠋ Setting the repository active stack to 'wandb_stack'...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change the stack to the mlflow stack\n",
    "!zenml stack set wandb_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Stack Configuration               \n",
      "┌────────────────────┬──────────────────────────┐\n",
      "│ COMPONENT_TYPE     │ COMPONENT_NAME           │\n",
      "├────────────────────┼──────────────────────────┤\n",
      "│ ARTIFACT_STORE     │ default                  │\n",
      "├────────────────────┼──────────────────────────┤\n",
      "│ EXPERIMENT_TRACKER │ wandb_experiment_tracker │\n",
      "├────────────────────┼──────────────────────────┤\n",
      "│ ORCHESTRATOR       │ default                  │\n",
      "└────────────────────┴──────────────────────────┘\n",
      "          'wandb_stack' stack (ACTIVE)           \n",
      "⠋ Describing the stack...\n",
      "\n",
      "           Labels           \n",
      "┌──────────────────┬───────┐\n",
      "│ LABEL            │ VALUE │\n",
      "├──────────────────┼───────┤\n",
      "│ zenml:full_stack │ True  │\n",
      "└──────────────────┴───────┘\n",
      "⠋ Describing the stack...\n",
      "\n",
      "Stack 'wandb_stack' with id '10466513-5196-4c4e-9403-e0334a3670a0' is owned by \n",
      "user default.\n",
      "⠋ Describing the stack...\n",
      "\n",
      "⠋ Describing the stack...\n",
      "\n",
      "\n",
      "You can display various ZenML entities including pipelines, runs, stacks and \n",
      "much more on the ZenML Dashboard. You can try it locally, by running `zenml \n",
      "up`, or remotely, by deploying ZenML on the infrastructure of your choice.\n"
     ]
    }
   ],
   "source": [
    "# At last we are going to check the status of the stack again\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import run_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mStarting the feature engineering pipeline.\u001b[0m\n",
      "\u001b[1;35mStarting feature engineering pipeline...\u001b[0m\n",
      "\u001b[1;35mData updated.\u001b[0m\n",
      "\u001b[1;35mFeature engineering pipeline successfully completed.\u001b[0m\n",
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 66)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mwandb_stack\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  experiment_tracker: \u001b[0m\u001b[1;36mwandb_experiment_tracker\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mupdate_data\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mupdate_data\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mload_data\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mload_data\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mcreate_derived_features\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_derived_features\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36msplit_data\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36msplit_data\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_preprocessing_pipeline\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStarting feature_preprocessor step...\u001b[0m\n",
      "\u001b[1;35mFeature preprocessor step successfully completed.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m6.888s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mfeature_preprocessor\u001b[1;35m completed successfully.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_eda_data\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_eda_data\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.584s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mcreate_eda_data\u001b[1;35m completed successfully.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m8.573s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mFeature engineering pipeline completed.\u001b[0m\n",
      "\u001b[1;35mStarting the training pipeline.\u001b[0m\n",
      "\u001b[1;35mStarting training_pipeline...\u001b[0m\n",
      "\u001b[1;35mFinished training_pipeline.\u001b[0m\n",
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 48)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mwandb_stack\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  experiment_tracker: \u001b[0m\u001b[1;36mwandb_experiment_tracker\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml up\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuning\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStarting hp_tuning step...\u001b[0m\n",
      "\u001b[1;35mModelltyp: xgboost\u001b[0m\n",
      "\u001b[1;35mAnzahl der Trials: 5\u001b[0m\n",
      "\u001b[1;35mForm von X_train: (11112, 40)\u001b[0m\n",
      "\u001b[1;35mForm von y_train: (11112,)\u001b[0m\n",
      "\u001b[1;35mDatentyp von y_train ist int64\u001b[0m\n",
      "\u001b[1;35mDatentyp von y_train.iloc[0] ist 1197\u001b[0m\n",
      "[I 2024-07-14 12:19:02,543] A new study created in memory with name: no-name-d38cc8da-1071-4054-a969-00eb6c1735ae\n",
      "[I 2024-07-14 12:19:04,071] Trial 0 finished with value: 160.4279718038049 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.1512732317574316, 'subsample': 0.7774596389723907, 'colsample_bytree': 0.7677472605607017}. Best is trial 0 with value: 160.4279718038049.\n",
      "[I 2024-07-14 12:19:04,278] Trial 1 finished with value: 257.3759585701275 and parameters: {'n_estimators': 185, 'max_depth': 2, 'learning_rate': 0.06548909093953259, 'subsample': 0.7376680778479845, 'colsample_bytree': 0.6379362238555185}. Best is trial 0 with value: 160.4279718038049.\n",
      "[I 2024-07-14 12:19:05,021] Trial 2 finished with value: 160.6024780803307 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.11364199924620653, 'subsample': 0.8616351115122554, 'colsample_bytree': 0.8445814005309107}. Best is trial 0 with value: 160.4279718038049.\n",
      "[I 2024-07-14 12:19:05,126] Trial 3 finished with value: 405.9583931527373 and parameters: {'n_estimators': 119, 'max_depth': 1, 'learning_rate': 0.10487063152360247, 'subsample': 0.8056960248900048, 'colsample_bytree': 0.7143572445908486}. Best is trial 0 with value: 160.4279718038049.\n",
      "[I 2024-07-14 12:19:05,495] Trial 4 finished with value: 170.52068921212415 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.11008132108139108, 'subsample': 0.6369546495163781, 'colsample_bytree': 0.6059670671637677}. Best is trial 0 with value: 160.4279718038049.\n",
      "\u001b[1;35mBest Hyperparameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.1512732317574316, 'subsample': 0.7774596389723907, 'colsample_bytree': 0.7677472605607017}\u001b[0m\n",
      "\u001b[1;35mHp-Tuning step successfully completed.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuning\u001b[1;35m has finished in \u001b[0m\u001b[1;36m3.084s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mhp_tuning\u001b[1;35m completed successfully.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.012s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m completed successfully.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mInitializing wandb with entity None, project name: None, run_name: training_pipeline-2024_07_14-10_19_02_427689_evaluate_model.\u001b[0m\n",
      "\u001b[31mFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatja-gegg\u001b[0m (\u001b[33mss24_eai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject\\wandb\\run-20240714_121912-wr08ubzi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ss24_eai/EAI-SS24-finalProject/runs/wr08ubzi' target=\"_blank\">training_pipeline-2024_07_14-10_19_02_427689_evaluate_model</a></strong> to <a href='https://wandb.ai/ss24_eai/EAI-SS24-finalProject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ss24_eai/EAI-SS24-finalProject' target=\"_blank\">https://wandb.ai/ss24_eai/EAI-SS24-finalProject</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ss24_eai/EAI-SS24-finalProject/runs/wr08ubzi' target=\"_blank\">https://wandb.ai/ss24_eai/EAI-SS24-finalProject/runs/wr08ubzi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mStarting evaluate_model step...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wr08ubzi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_pipeline-2024_07_14-10_19_02_427689_evaluate_model</strong> at: <a href='https://wandb.ai/ss24_eai/EAI-SS24-finalProject/runs/wr08ubzi' target=\"_blank\">https://wandb.ai/ss24_eai/EAI-SS24-finalProject/runs/wr08ubzi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240714_121912-wr08ubzi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wr08ubzi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d472916362a4eeb9ee4596c7d707e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject\\wandb\\run-20240714_121913-76tap9vg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ss24_eai/forcasting_model_multivariant/runs/76tap9vg' target=\"_blank\">m_xgboost_2_lags_5_trials</a></strong> to <a href='https://wandb.ai/ss24_eai/forcasting_model_multivariant' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ss24_eai/forcasting_model_multivariant' target=\"_blank\">https://wandb.ai/ss24_eai/forcasting_model_multivariant</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ss24_eai/forcasting_model_multivariant/runs/76tap9vg' target=\"_blank\">https://wandb.ai/ss24_eai/forcasting_model_multivariant/runs/76tap9vg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mDeployment decision: True\u001b[0m\n",
      "\u001b[1;35mFinished evaluate_model step.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>deployment_decision</td><td>▁</td></tr><tr><td>in_sample_rmse</td><td>▁</td></tr><tr><td>lags</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>mae</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>mse</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>trials</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>colsample_bytree</td><td>0.76775</td></tr><tr><td>deployment_decision</td><td>True</td></tr><tr><td>in_sample_rmse</td><td>84.73858</td></tr><tr><td>lags</td><td>2</td></tr><tr><td>learning_rate</td><td>0.15127</td></tr><tr><td>mae</td><td>123.06201</td></tr><tr><td>max_depth</td><td>6</td></tr><tr><td>model_type</td><td>xgboost</td></tr><tr><td>model_variant</td><td>multi</td></tr><tr><td>mse</td><td>41856.33311</td></tr><tr><td>n_estimators</td><td>134</td></tr><tr><td>r2</td><td>0.94652</td></tr><tr><td>rmse</td><td>204.5882</td></tr><tr><td>subsample</td><td>0.77746</td></tr><tr><td>trials</td><td>5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">m_xgboost_2_lags_5_trials</strong> at: <a href='https://wandb.ai/ss24_eai/forcasting_model_multivariant/runs/76tap9vg' target=\"_blank\">https://wandb.ai/ss24_eai/forcasting_model_multivariant/runs/76tap9vg</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240714_121913-76tap9vg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m has finished in \u001b[0m\u001b[1;36m17.295s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mevaluate_model\u001b[1;35m completed successfully.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m25.733s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mTraining pipeline completed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Set the model variant and type\n",
    "#m_variant = \"uni\"\n",
    "m_variant = \"multi\"\n",
    "m_type = \"xgboost\"\n",
    "#m_type = \"random_forest\"\n",
    "lags = 5\n",
    "tials = 1\n",
    "\n",
    "run_pipelines(model_variant=m_variant, model_type=m_type, lags=lags, trials=tials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: wandb agent [OPTIONS] SWEEP_ID\n",
      "\n",
      "  Run the W&B agent\n",
      "\n",
      "Options:\n",
      "  -p, --project TEXT  The project of the sweep.\n",
      "  -e, --entity TEXT   The entity scope for the project.\n",
      "  --count INTEGER     The max number of runs for this agent.\n",
      "  --help              Show this message and exit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Starting wandb agent 🕵️\n",
      "wandb: ERROR Error while calling W&B API: entityName required for project query (<Response [400]>)\n",
      "wandb: ERROR Find detailed error logs at: c:\\Users\\User\\VSCProjects\\EAI_SS24\\EAI-SS24-finalProject\\wandb\\debug-cli.User.log\n",
      "Error: entityName required for project query (Error 400: Bad Request)\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to visualize the pipeline runs in wandb\n",
    "#project_name = \"forecasting_model_mutivariant\"\n",
    "\n",
    "#!wandb agent $project_name/forecasting_model_multivariant --count 1 --project $project_name --queue forecasting_model_multivariant --entity $project_name --start-time now --duration 1h\n",
    "#!wandb agent --help\n",
    "#!wandb agent -p forecasting_model_multivariant abc123\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wandb.ai/None/None/runs/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from zenml.client import Client\n",
    "# pipeline_run = Client().get_pipeline(\"training_pipeline\").last_run\n",
    "# step = pipeline_run.steps[\"evaluate_model\"]\n",
    "# experiment_tracker_url = step.run_metadata[\"experiment_tracker_url\"].value\n",
    "# experiment_tracker_url # jedes mal wenn code space neu geöffnet wird ändert sich dieser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "# from zenml.client import Client\n",
    "\n",
    "# client = Client()\n",
    "# report = client.get_artifact_version(\"training_pipeline\").load()\n",
    "\n",
    "# display(HTML(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nun erst die inference = Using the best model????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
